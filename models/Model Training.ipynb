{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7400396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 95 images belonging to 2 classes.\n",
      "Found 72 images belonging to 2 classes.\n",
      "2 2\n",
      "WARNING:tensorflow:From C:\\Users\\gaura\\AppData\\Local\\Temp/ipykernel_1728/3651055231.py:53: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "2/2 [==============================] - 1s 642ms/step - loss: 0.7012 - accuracy: 0.4921 - val_loss: 0.7951 - val_accuracy: 0.4844\n",
      "Epoch 2/15\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6982 - accuracy: 0.4762 - val_loss: 0.7275 - val_accuracy: 0.4844\n",
      "Epoch 3/15\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6627 - accuracy: 0.6508 - val_loss: 0.6847 - val_accuracy: 0.5156\n",
      "Epoch 4/15\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6538 - accuracy: 0.7302 - val_loss: 0.6756 - val_accuracy: 0.5781\n",
      "Epoch 5/15\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.5902 - accuracy: 0.8438 - val_loss: 0.7096 - val_accuracy: 0.5312\n",
      "Epoch 6/15\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.4851 - accuracy: 0.8125 - val_loss: 0.7037 - val_accuracy: 0.5469\n",
      "Epoch 7/15\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.3931 - accuracy: 0.9841 - val_loss: 0.7453 - val_accuracy: 0.6719\n",
      "Epoch 8/15\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2651 - accuracy: 0.9683 - val_loss: 0.9430 - val_accuracy: 0.5938\n",
      "Epoch 9/15\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.2926 - accuracy: 0.8571 - val_loss: 0.9753 - val_accuracy: 0.5625\n",
      "Epoch 10/15\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.1600 - accuracy: 0.9683 - val_loss: 1.3175 - val_accuracy: 0.5312\n",
      "Epoch 11/15\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.1042 - accuracy: 0.9683 - val_loss: 1.2763 - val_accuracy: 0.6250\n",
      "Epoch 12/15\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0725 - accuracy: 0.9683 - val_loss: 1.5534 - val_accuracy: 0.5781\n",
      "Epoch 13/15\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 2.3094 - val_accuracy: 0.5312\n",
      "Epoch 14/15\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0420 - accuracy: 0.9844 - val_loss: 2.9395 - val_accuracy: 0.5156\n",
      "Epoch 15/15\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.1010 - accuracy: 0.9841 - val_loss: 2.5446 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import random,shutil\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Conv2D,Flatten,Dense, MaxPooling2D, BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),class_mode='categorical'):\n",
    "    return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',class_mode=class_mode,target_size=target_size)\n",
    "\n",
    "BS= 32 \n",
    "TS=(24,24)\n",
    "train_batch= generator('data/train',shuffle=True, batch_size=BS,target_size=TS)\n",
    "valid_batch= generator('data/valid',shuffle=True, batch_size=BS,target_size=TS)\n",
    "SPE= len(train_batch.classes)//BS\n",
    "VS = len(valid_batch.classes)//BS\n",
    "print(SPE,VS)\n",
    "\n",
    "# img,labels= next(train_batch)\n",
    "# print(img.shape)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    Conv2D(32,(3,3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "#32 convolution filters used each of size 3x3\n",
    "#again\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(1,1)),\n",
    "    \n",
    "#64 convolution filters used each of size 3x3\n",
    "#choose the best features via pooling\n",
    "    \n",
    "#randomly turn neurons on and off to improve convergence\n",
    "    Dropout(0.25),\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "    Flatten(),\n",
    "#fully connected to get all relevant data\n",
    "    Dense(128, activation='relu'),\n",
    "#one more dropout for convergence' sake :) \n",
    "    Dropout(0.5),\n",
    "#output a softmax to squash the matrix into output probabilities\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train_batch, validation_data=valid_batch,epochs=15,steps_per_epoch=SPE ,validation_steps=VS)\n",
    "\n",
    "model.save('models/cnnCat2.h5', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
